{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R6_InternalLab_AIML_Iris_tf_Keras_Sample_Solution.ipynb","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YJRBuqXhOB7_"},"source":["## Classification using tf.Keras\n","\n","In this exercise, we will build a Linear Classifier using tf.Keras. We will use Iris Dataset for this exercise."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sb7Epo0VOB58"},"source":["### Load tensorflow"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fHpCNRv1OB5-","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O0g6lorycihf","colab_type":"text"},"source":["### Load the given Iris data using pandas (Iris.csv)"]},{"cell_type":"code","metadata":{"id":"6xFvb5sRcihg","colab_type":"code","outputId":"9972e4ca-5fbd-4a9e-cafc-bf42c74b41e4","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ybYu-0R4e3GY","colab_type":"code","colab":{}},"source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAIuF4qve7aC","colab_type":"code","colab":{}},"source":["data = pd.read_csv('/gdrive/My Drive/Great Learning/Neural Networks I/Lab Solution/11_Iris.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"05OYq0myfJaH","colab_type":"code","outputId":"4efef163-3825-49e0-9c85-5cb3c6e49191","colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>SepalLengthCm</th>\n","      <th>SepalWidthCm</th>\n","      <th>PetalLengthCm</th>\n","      <th>PetalWidthCm</th>\n","      <th>Species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n","0   1            5.1           3.5            1.4           0.2  Iris-setosa\n","1   2            4.9           3.0            1.4           0.2  Iris-setosa\n","2   3            4.7           3.2            1.3           0.2  Iris-setosa\n","3   4            4.6           3.1            1.5           0.2  Iris-setosa\n","4   5            5.0           3.6            1.4           0.2  Iris-setosa"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"SAB--Qdwcihm","colab_type":"text"},"source":["### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."]},{"cell_type":"code","metadata":{"id":"RyMQoLMucihj","colab_type":"code","outputId":"26a4ebc6-166f-4440-879c-de8e822f364f","colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["df = pd.get_dummies(data, columns=['Species'])\n","\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>SepalLengthCm</th>\n","      <th>SepalWidthCm</th>\n","      <th>PetalLengthCm</th>\n","      <th>PetalWidthCm</th>\n","      <th>Species_Iris-setosa</th>\n","      <th>Species_Iris-versicolor</th>\n","      <th>Species_Iris-virginica</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n","0   1            5.1           3.5            1.4           0.2   \n","1   2            4.9           3.0            1.4           0.2   \n","2   3            4.7           3.2            1.3           0.2   \n","3   4            4.6           3.1            1.5           0.2   \n","4   5            5.0           3.6            1.4           0.2   \n","\n","   Species_Iris-setosa  Species_Iris-versicolor  Species_Iris-virginica  \n","0                    1                        0                       0  \n","1                    1                        0                       0  \n","2                    1                        0                       0  \n","3                    1                        0                       0  \n","4                    1                        0                       0  "]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"D95nY5ILcihj","colab_type":"text"},"source":["### Splitting the data into feature set and target set"]},{"cell_type":"code","metadata":{"id":"gKGvUWahcihp","colab_type":"code","colab":{}},"source":["X = df[['SepalLengthCm','SepalWidthCm', 'PetalLengthCm','PetalWidthCm']]\n","y = df[['Species_Iris-setosa', 'Species_Iris-versicolor', 'Species_Iris-virginica']]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ERq9GOKKciho","colab_type":"text"},"source":["### Divide the dataset into Training and test (70:30)"]},{"cell_type":"code","metadata":{"id":"IJr5dYnocihm","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b22qpC5xcihr","colab_type":"text"},"source":["###  Building Model in tf.keras\n","\n","Build the model with following layers: <br>\n","1. First add a BatchNormalization Layer with input shape of 4 (according to the feature set)<br> \n","2. 1st hidden Layer - Dense layer with 10 neurons <br>\n","3. 2nd hidden layer - Dense layer with 8 neurons <br>\n","4. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n","5. Use SGD as Optimizer\n","6. Use categorical_crossentropy as loss function "]},{"cell_type":"code","metadata":{"id":"Hov_UFnUciht","colab_type":"code","outputId":"a9d855d0-2653-4fe7-ec89-c67e8ad1b669","colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Dense(3, input_shape=(4,), activation='softmax'))\n","model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['acc'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p2-tLcHDjcQA","colab_type":"text"},"source":["### Use Model Summary to check model layers, understand number of trainable parameters"]},{"cell_type":"code","metadata":{"id":"V79AqEMjjlpQ","colab_type":"code","outputId":"8f201617-9869-4ac9-d0ad-05dadf9ebda7","colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 3)                 15        \n","=================================================================\n","Total params: 15\n","Trainable params: 15\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T5FdzqIKcihw","colab_type":"text"},"source":["### Model Training "]},{"cell_type":"code","metadata":{"id":"4qLEdHPscihx","colab_type":"code","outputId":"dc9e594b-d04b-41ee-84c0-7f82e59e0e92","colab":{"base_uri":"https://localhost:8080/","height":6841}},"source":["model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 105 samples, validate on 45 samples\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/200\n","105/105 [==============================] - 0s 948us/sample - loss: 3.3594 - acc: 0.3524 - val_loss: 3.7421 - val_acc: 0.2889\n","Epoch 2/200\n","105/105 [==============================] - 0s 118us/sample - loss: 2.7788 - acc: 0.3524 - val_loss: 3.2514 - val_acc: 0.2889\n","Epoch 3/200\n","105/105 [==============================] - 0s 108us/sample - loss: 2.3604 - acc: 0.3524 - val_loss: 2.8973 - val_acc: 0.2889\n","Epoch 4/200\n","105/105 [==============================] - 0s 116us/sample - loss: 2.0959 - acc: 0.3714 - val_loss: 2.6303 - val_acc: 0.3778\n","Epoch 5/200\n","105/105 [==============================] - 0s 101us/sample - loss: 1.8991 - acc: 0.4857 - val_loss: 2.2747 - val_acc: 0.3556\n","Epoch 6/200\n","105/105 [==============================] - 0s 100us/sample - loss: 1.6631 - acc: 0.4571 - val_loss: 1.9931 - val_acc: 0.3556\n","Epoch 7/200\n","105/105 [==============================] - 0s 102us/sample - loss: 1.4725 - acc: 0.4667 - val_loss: 1.7080 - val_acc: 0.4000\n","Epoch 8/200\n","105/105 [==============================] - 0s 90us/sample - loss: 1.2804 - acc: 0.5048 - val_loss: 1.4939 - val_acc: 0.4667\n","Epoch 9/200\n","105/105 [==============================] - 0s 102us/sample - loss: 1.1297 - acc: 0.6000 - val_loss: 1.2309 - val_acc: 0.4444\n","Epoch 10/200\n","105/105 [==============================] - 0s 104us/sample - loss: 0.9811 - acc: 0.5429 - val_loss: 1.0483 - val_acc: 0.3778\n","Epoch 11/200\n","105/105 [==============================] - 0s 95us/sample - loss: 0.8741 - acc: 0.5143 - val_loss: 0.9091 - val_acc: 0.3778\n","Epoch 12/200\n","105/105 [==============================] - 0s 83us/sample - loss: 0.8009 - acc: 0.5143 - val_loss: 0.8074 - val_acc: 0.3778\n","Epoch 13/200\n","105/105 [==============================] - 0s 87us/sample - loss: 0.7561 - acc: 0.4571 - val_loss: 0.7714 - val_acc: 0.4444\n","Epoch 14/200\n","105/105 [==============================] - 0s 83us/sample - loss: 0.7364 - acc: 0.5429 - val_loss: 0.7288 - val_acc: 0.4889\n","Epoch 15/200\n","105/105 [==============================] - 0s 107us/sample - loss: 0.7222 - acc: 0.5714 - val_loss: 0.7200 - val_acc: 0.5111\n","Epoch 16/200\n","105/105 [==============================] - 0s 126us/sample - loss: 0.7190 - acc: 0.5524 - val_loss: 0.6984 - val_acc: 0.7333\n","Epoch 17/200\n","105/105 [==============================] - 0s 149us/sample - loss: 0.7035 - acc: 0.7238 - val_loss: 0.6915 - val_acc: 0.7333\n","Epoch 18/200\n","105/105 [==============================] - 0s 108us/sample - loss: 0.6962 - acc: 0.7524 - val_loss: 0.6718 - val_acc: 0.8889\n","Epoch 19/200\n","105/105 [==============================] - 0s 101us/sample - loss: 0.6816 - acc: 0.8476 - val_loss: 0.6683 - val_acc: 0.8444\n","Epoch 20/200\n","105/105 [==============================] - 0s 98us/sample - loss: 0.6744 - acc: 0.9048 - val_loss: 0.6496 - val_acc: 0.8222\n","Epoch 21/200\n","105/105 [==============================] - 0s 121us/sample - loss: 0.6707 - acc: 0.8286 - val_loss: 0.6408 - val_acc: 0.8222\n","Epoch 22/200\n","105/105 [==============================] - 0s 107us/sample - loss: 0.6599 - acc: 0.8095 - val_loss: 0.6367 - val_acc: 0.8889\n","Epoch 23/200\n","105/105 [==============================] - 0s 116us/sample - loss: 0.6571 - acc: 0.8286 - val_loss: 0.6240 - val_acc: 0.8889\n","Epoch 24/200\n","105/105 [==============================] - 0s 121us/sample - loss: 0.6449 - acc: 0.8952 - val_loss: 0.6283 - val_acc: 1.0000\n","Epoch 25/200\n","105/105 [==============================] - 0s 148us/sample - loss: 0.6405 - acc: 0.9524 - val_loss: 0.6060 - val_acc: 0.9111\n","Epoch 26/200\n","105/105 [==============================] - 0s 115us/sample - loss: 0.6290 - acc: 0.9143 - val_loss: 0.6024 - val_acc: 0.9778\n","Epoch 27/200\n","105/105 [==============================] - 0s 140us/sample - loss: 0.6243 - acc: 0.9238 - val_loss: 0.5917 - val_acc: 0.8889\n","Epoch 28/200\n","105/105 [==============================] - 0s 120us/sample - loss: 0.6184 - acc: 0.8286 - val_loss: 0.5895 - val_acc: 0.8889\n","Epoch 29/200\n","105/105 [==============================] - 0s 92us/sample - loss: 0.6124 - acc: 0.8857 - val_loss: 0.5819 - val_acc: 0.8889\n","Epoch 30/200\n","105/105 [==============================] - 0s 101us/sample - loss: 0.6147 - acc: 0.9143 - val_loss: 0.5748 - val_acc: 0.8444\n","Epoch 31/200\n","105/105 [==============================] - 0s 92us/sample - loss: 0.6051 - acc: 0.8476 - val_loss: 0.5750 - val_acc: 0.8889\n","Epoch 32/200\n","105/105 [==============================] - 0s 98us/sample - loss: 0.5988 - acc: 0.9238 - val_loss: 0.5693 - val_acc: 0.8889\n","Epoch 33/200\n","105/105 [==============================] - 0s 97us/sample - loss: 0.5944 - acc: 0.8952 - val_loss: 0.5623 - val_acc: 0.9111\n","Epoch 34/200\n","105/105 [==============================] - 0s 107us/sample - loss: 0.5919 - acc: 0.8952 - val_loss: 0.5537 - val_acc: 0.9778\n","Epoch 35/200\n","105/105 [==============================] - 0s 122us/sample - loss: 0.5862 - acc: 0.9143 - val_loss: 0.5412 - val_acc: 0.8889\n","Epoch 36/200\n","105/105 [==============================] - 0s 109us/sample - loss: 0.5808 - acc: 0.8857 - val_loss: 0.5389 - val_acc: 0.9111\n","Epoch 37/200\n","105/105 [==============================] - 0s 100us/sample - loss: 0.5766 - acc: 0.9048 - val_loss: 0.5499 - val_acc: 0.9778\n","Epoch 38/200\n","105/105 [==============================] - 0s 138us/sample - loss: 0.5797 - acc: 0.9429 - val_loss: 0.5290 - val_acc: 0.9111\n","Epoch 39/200\n","105/105 [==============================] - 0s 107us/sample - loss: 0.5706 - acc: 0.9048 - val_loss: 0.5260 - val_acc: 0.8889\n","Epoch 40/200\n","105/105 [==============================] - 0s 106us/sample - loss: 0.5641 - acc: 0.8571 - val_loss: 0.5215 - val_acc: 1.0000\n","Epoch 41/200\n","105/105 [==============================] - 0s 121us/sample - loss: 0.5601 - acc: 0.9333 - val_loss: 0.5124 - val_acc: 0.8889\n","Epoch 42/200\n","105/105 [==============================] - 0s 148us/sample - loss: 0.5573 - acc: 0.9048 - val_loss: 0.5098 - val_acc: 0.9778\n","Epoch 43/200\n","105/105 [==============================] - 0s 104us/sample - loss: 0.5536 - acc: 0.9143 - val_loss: 0.5156 - val_acc: 0.9778\n","Epoch 44/200\n","105/105 [==============================] - 0s 109us/sample - loss: 0.5580 - acc: 0.9333 - val_loss: 0.5024 - val_acc: 0.8889\n","Epoch 45/200\n","105/105 [==============================] - 0s 93us/sample - loss: 0.5474 - acc: 0.9143 - val_loss: 0.5079 - val_acc: 0.8000\n","Epoch 46/200\n","105/105 [==============================] - 0s 115us/sample - loss: 0.5506 - acc: 0.8190 - val_loss: 0.4957 - val_acc: 0.8889\n","Epoch 47/200\n","105/105 [==============================] - 0s 107us/sample - loss: 0.5433 - acc: 0.8762 - val_loss: 0.4935 - val_acc: 0.9778\n","Epoch 48/200\n","105/105 [==============================] - 0s 108us/sample - loss: 0.5378 - acc: 0.9429 - val_loss: 0.4922 - val_acc: 0.8222\n","Epoch 49/200\n","105/105 [==============================] - 0s 132us/sample - loss: 0.5380 - acc: 0.8381 - val_loss: 0.4846 - val_acc: 0.9111\n","Epoch 50/200\n","105/105 [==============================] - 0s 126us/sample - loss: 0.5307 - acc: 0.9143 - val_loss: 0.4792 - val_acc: 0.8889\n","Epoch 51/200\n","105/105 [==============================] - 0s 100us/sample - loss: 0.5285 - acc: 0.8762 - val_loss: 0.4773 - val_acc: 0.9778\n","Epoch 52/200\n","105/105 [==============================] - 0s 100us/sample - loss: 0.5267 - acc: 0.9333 - val_loss: 0.4787 - val_acc: 1.0000\n","Epoch 53/200\n","105/105 [==============================] - 0s 103us/sample - loss: 0.5300 - acc: 0.9143 - val_loss: 0.4727 - val_acc: 0.9111\n","Epoch 54/200\n","105/105 [==============================] - 0s 95us/sample - loss: 0.5213 - acc: 0.9238 - val_loss: 0.4706 - val_acc: 0.9111\n","Epoch 55/200\n","105/105 [==============================] - 0s 110us/sample - loss: 0.5178 - acc: 0.9143 - val_loss: 0.4676 - val_acc: 0.9111\n","Epoch 56/200\n","105/105 [==============================] - 0s 100us/sample - loss: 0.5202 - acc: 0.8762 - val_loss: 0.4691 - val_acc: 1.0000\n","Epoch 57/200\n","105/105 [==============================] - 0s 103us/sample - loss: 0.5146 - acc: 0.9429 - val_loss: 0.4619 - val_acc: 0.9111\n","Epoch 58/200\n","105/105 [==============================] - 0s 100us/sample - loss: 0.5133 - acc: 0.9333 - val_loss: 0.4598 - val_acc: 0.9111\n","Epoch 59/200\n","105/105 [==============================] - 0s 101us/sample - loss: 0.5088 - acc: 0.9238 - val_loss: 0.4546 - val_acc: 0.9111\n","Epoch 60/200\n","105/105 [==============================] - 0s 92us/sample - loss: 0.5067 - acc: 0.9143 - val_loss: 0.4515 - val_acc: 0.8889\n","Epoch 61/200\n","105/105 [==============================] - 0s 121us/sample - loss: 0.5072 - acc: 0.9048 - val_loss: 0.4496 - val_acc: 0.9111\n","Epoch 62/200\n","105/105 [==============================] - 0s 107us/sample - loss: 0.5034 - acc: 0.8952 - val_loss: 0.4480 - val_acc: 0.9778\n","Epoch 63/200\n","105/105 [==============================] - 0s 141us/sample - loss: 0.5030 - acc: 0.8952 - val_loss: 0.4484 - val_acc: 1.0000\n","Epoch 64/200\n","105/105 [==============================] - 0s 118us/sample - loss: 0.5014 - acc: 0.9333 - val_loss: 0.4430 - val_acc: 0.9333\n","Epoch 65/200\n","105/105 [==============================] - 0s 118us/sample - loss: 0.5001 - acc: 0.9238 - val_loss: 0.4421 - val_acc: 0.8889\n","Epoch 66/200\n","105/105 [==============================] - 0s 95us/sample - loss: 0.4965 - acc: 0.8476 - val_loss: 0.4381 - val_acc: 0.8889\n","Epoch 67/200\n","105/105 [==============================] - 0s 89us/sample - loss: 0.4931 - acc: 0.8952 - val_loss: 0.4359 - val_acc: 0.9111\n","Epoch 68/200\n","105/105 [==============================] - 0s 113us/sample - loss: 0.4927 - acc: 0.9143 - val_loss: 0.4333 - val_acc: 0.9111\n","Epoch 69/200\n","105/105 [==============================] - 0s 106us/sample - loss: 0.4896 - acc: 0.9143 - val_loss: 0.4329 - val_acc: 0.9111\n","Epoch 70/200\n","105/105 [==============================] - 0s 98us/sample - loss: 0.4877 - acc: 0.9429 - val_loss: 0.4310 - val_acc: 0.9111\n","Epoch 71/200\n","105/105 [==============================] - 0s 112us/sample - loss: 0.4850 - acc: 0.9238 - val_loss: 0.4285 - val_acc: 0.9111\n","Epoch 72/200\n","105/105 [==============================] - 0s 115us/sample - loss: 0.4863 - acc: 0.9048 - val_loss: 0.4294 - val_acc: 1.0000\n","Epoch 73/200\n","105/105 [==============================] - 0s 104us/sample - loss: 0.4885 - acc: 0.9333 - val_loss: 0.4331 - val_acc: 0.9778\n","Epoch 74/200\n","105/105 [==============================] - 0s 91us/sample - loss: 0.4861 - acc: 0.9238 - val_loss: 0.4250 - val_acc: 1.0000\n","Epoch 75/200\n","105/105 [==============================] - 0s 105us/sample - loss: 0.4803 - acc: 0.9524 - val_loss: 0.4202 - val_acc: 0.9778\n","Epoch 76/200\n","105/105 [==============================] - 0s 88us/sample - loss: 0.4771 - acc: 0.9524 - val_loss: 0.4193 - val_acc: 0.8889\n","Epoch 77/200\n","105/105 [==============================] - 0s 94us/sample - loss: 0.4781 - acc: 0.9143 - val_loss: 0.4177 - val_acc: 0.9111\n","Epoch 78/200\n","105/105 [==============================] - 0s 88us/sample - loss: 0.4742 - acc: 0.9333 - val_loss: 0.4149 - val_acc: 0.9111\n","Epoch 79/200\n","105/105 [==============================] - 0s 118us/sample - loss: 0.4741 - acc: 0.9333 - val_loss: 0.4135 - val_acc: 0.9111\n","Epoch 80/200\n","105/105 [==============================] - 0s 102us/sample - loss: 0.4728 - acc: 0.9333 - val_loss: 0.4125 - val_acc: 0.8889\n","Epoch 81/200\n","105/105 [==============================] - 0s 151us/sample - loss: 0.4707 - acc: 0.8762 - val_loss: 0.4115 - val_acc: 1.0000\n","Epoch 82/200\n","105/105 [==============================] - 0s 95us/sample - loss: 0.4692 - acc: 0.9429 - val_loss: 0.4085 - val_acc: 0.9778\n","Epoch 83/200\n","105/105 [==============================] - 0s 106us/sample - loss: 0.4668 - acc: 0.9429 - val_loss: 0.4065 - val_acc: 0.9778\n","Epoch 84/200\n","105/105 [==============================] - 0s 102us/sample - loss: 0.4668 - acc: 0.9429 - val_loss: 0.4044 - val_acc: 0.9111\n","Epoch 85/200\n","105/105 [==============================] - 0s 112us/sample - loss: 0.4682 - acc: 0.9143 - val_loss: 0.4037 - val_acc: 0.8889\n","Epoch 86/200\n","105/105 [==============================] - 0s 94us/sample - loss: 0.4641 - acc: 0.9238 - val_loss: 0.4049 - val_acc: 0.8889\n","Epoch 87/200\n","105/105 [==============================] - 0s 97us/sample - loss: 0.4672 - acc: 0.8571 - val_loss: 0.4003 - val_acc: 0.9778\n","Epoch 88/200\n","105/105 [==============================] - 0s 108us/sample - loss: 0.4605 - acc: 0.9429 - val_loss: 0.4008 - val_acc: 0.8889\n","Epoch 89/200\n","105/105 [==============================] - 0s 109us/sample - loss: 0.4621 - acc: 0.9048 - val_loss: 0.3973 - val_acc: 0.9111\n","Epoch 90/200\n","105/105 [==============================] - 0s 131us/sample - loss: 0.4580 - acc: 0.9238 - val_loss: 0.3964 - val_acc: 0.9111\n","Epoch 91/200\n","105/105 [==============================] - 0s 119us/sample - loss: 0.4602 - acc: 0.9333 - val_loss: 0.3964 - val_acc: 0.9778\n","Epoch 92/200\n","105/105 [==============================] - 0s 119us/sample - loss: 0.4543 - acc: 0.9429 - val_loss: 0.3950 - val_acc: 0.9111\n","Epoch 93/200\n","105/105 [==============================] - 0s 120us/sample - loss: 0.4548 - acc: 0.9238 - val_loss: 0.3931 - val_acc: 0.9111\n","Epoch 94/200\n","105/105 [==============================] - 0s 95us/sample - loss: 0.4528 - acc: 0.9333 - val_loss: 0.3923 - val_acc: 0.9778\n","Epoch 95/200\n","105/105 [==============================] - 0s 137us/sample - loss: 0.4519 - acc: 0.9429 - val_loss: 0.3915 - val_acc: 0.9778\n","Epoch 96/200\n","105/105 [==============================] - 0s 95us/sample - loss: 0.4521 - acc: 0.9524 - val_loss: 0.3891 - val_acc: 0.9556\n","Epoch 97/200\n","105/105 [==============================] - 0s 91us/sample - loss: 0.4484 - acc: 0.9238 - val_loss: 0.3875 - val_acc: 0.9333\n","Epoch 98/200\n","105/105 [==============================] - 0s 95us/sample - loss: 0.4502 - acc: 0.9333 - val_loss: 0.3864 - val_acc: 0.9778\n","Epoch 99/200\n","105/105 [==============================] - 0s 90us/sample - loss: 0.4497 - acc: 0.9238 - val_loss: 0.3849 - val_acc: 0.9778\n","Epoch 100/200\n","105/105 [==============================] - 0s 98us/sample - loss: 0.4482 - acc: 0.9524 - val_loss: 0.3853 - val_acc: 1.0000\n","Epoch 101/200\n","105/105 [==============================] - 0s 98us/sample - loss: 0.4461 - acc: 0.9333 - val_loss: 0.3831 - val_acc: 0.9111\n","Epoch 102/200\n","105/105 [==============================] - 0s 101us/sample - loss: 0.4439 - acc: 0.9143 - val_loss: 0.3828 - val_acc: 1.0000\n","Epoch 103/200\n","105/105 [==============================] - 0s 116us/sample - loss: 0.4428 - acc: 0.9333 - val_loss: 0.3796 - val_acc: 0.9778\n","Epoch 104/200\n","105/105 [==============================] - 0s 104us/sample - loss: 0.4430 - acc: 0.9524 - val_loss: 0.3781 - val_acc: 0.9778\n","Epoch 105/200\n","105/105 [==============================] - 0s 107us/sample - loss: 0.4413 - acc: 0.9429 - val_loss: 0.3771 - val_acc: 0.9778\n","Epoch 106/200\n","105/105 [==============================] - 0s 101us/sample - loss: 0.4412 - acc: 0.9429 - val_loss: 0.3794 - val_acc: 0.9778\n","Epoch 107/200\n","105/105 [==============================] - 0s 127us/sample - loss: 0.4474 - acc: 0.9429 - val_loss: 0.3750 - val_acc: 0.9778\n","Epoch 108/200\n","105/105 [==============================] - 0s 88us/sample - loss: 0.4381 - acc: 0.9333 - val_loss: 0.3743 - val_acc: 1.0000\n","Epoch 109/200\n","105/105 [==============================] - 0s 93us/sample - loss: 0.4359 - acc: 0.9524 - val_loss: 0.3733 - val_acc: 0.9556\n","Epoch 110/200\n","105/105 [==============================] - 0s 102us/sample - loss: 0.4357 - acc: 0.9429 - val_loss: 0.3729 - val_acc: 0.9111\n","Epoch 111/200\n","105/105 [==============================] - 0s 106us/sample - loss: 0.4344 - acc: 0.9143 - val_loss: 0.3737 - val_acc: 1.0000\n","Epoch 112/200\n","105/105 [==============================] - 0s 100us/sample - loss: 0.4346 - acc: 0.9524 - val_loss: 0.3700 - val_acc: 0.9778\n","Epoch 113/200\n","105/105 [==============================] - 0s 141us/sample - loss: 0.4321 - acc: 0.9333 - val_loss: 0.3691 - val_acc: 0.9778\n","Epoch 114/200\n","105/105 [==============================] - 0s 126us/sample - loss: 0.4345 - acc: 0.9333 - val_loss: 0.3679 - val_acc: 0.9778\n","Epoch 115/200\n","105/105 [==============================] - 0s 113us/sample - loss: 0.4307 - acc: 0.9429 - val_loss: 0.3704 - val_acc: 0.8889\n","Epoch 116/200\n","105/105 [==============================] - 0s 89us/sample - loss: 0.4314 - acc: 0.8952 - val_loss: 0.3657 - val_acc: 0.9778\n","Epoch 117/200\n","105/105 [==============================] - 0s 101us/sample - loss: 0.4284 - acc: 0.9429 - val_loss: 0.3648 - val_acc: 0.9333\n","Epoch 118/200\n","105/105 [==============================] - 0s 115us/sample - loss: 0.4318 - acc: 0.9333 - val_loss: 0.3635 - val_acc: 0.9778\n","Epoch 119/200\n","105/105 [==============================] - 0s 92us/sample - loss: 0.4279 - acc: 0.9333 - val_loss: 0.3624 - val_acc: 0.9778\n","Epoch 120/200\n","105/105 [==============================] - 0s 142us/sample - loss: 0.4265 - acc: 0.9429 - val_loss: 0.3616 - val_acc: 0.9778\n","Epoch 121/200\n","105/105 [==============================] - 0s 123us/sample - loss: 0.4287 - acc: 0.9333 - val_loss: 0.3613 - val_acc: 0.9556\n","Epoch 122/200\n","105/105 [==============================] - 0s 139us/sample - loss: 0.4257 - acc: 0.9333 - val_loss: 0.3612 - val_acc: 0.9111\n","Epoch 123/200\n","105/105 [==============================] - 0s 113us/sample - loss: 0.4241 - acc: 0.9429 - val_loss: 0.3607 - val_acc: 0.9111\n","Epoch 124/200\n","105/105 [==============================] - 0s 108us/sample - loss: 0.4239 - acc: 0.9429 - val_loss: 0.3606 - val_acc: 0.9111\n","Epoch 125/200\n","105/105 [==============================] - 0s 105us/sample - loss: 0.4223 - acc: 0.9238 - val_loss: 0.3585 - val_acc: 0.9333\n","Epoch 126/200\n","105/105 [==============================] - 0s 102us/sample - loss: 0.4227 - acc: 0.9333 - val_loss: 0.3619 - val_acc: 0.8889\n","Epoch 127/200\n","105/105 [==============================] - 0s 133us/sample - loss: 0.4226 - acc: 0.8952 - val_loss: 0.3582 - val_acc: 0.9111\n","Epoch 128/200\n","105/105 [==============================] - 0s 114us/sample - loss: 0.4221 - acc: 0.9048 - val_loss: 0.3581 - val_acc: 1.0000\n","Epoch 129/200\n","105/105 [==============================] - 0s 103us/sample - loss: 0.4197 - acc: 0.9333 - val_loss: 0.3556 - val_acc: 0.9778\n","Epoch 130/200\n","105/105 [==============================] - 0s 109us/sample - loss: 0.4170 - acc: 0.9429 - val_loss: 0.3561 - val_acc: 1.0000\n","Epoch 131/200\n","105/105 [==============================] - 0s 116us/sample - loss: 0.4173 - acc: 0.9524 - val_loss: 0.3564 - val_acc: 1.0000\n","Epoch 132/200\n","105/105 [==============================] - 0s 106us/sample - loss: 0.4176 - acc: 0.9429 - val_loss: 0.3562 - val_acc: 1.0000\n","Epoch 133/200\n","105/105 [==============================] - 0s 140us/sample - loss: 0.4167 - acc: 0.9429 - val_loss: 0.3531 - val_acc: 0.9778\n","Epoch 134/200\n","105/105 [==============================] - 0s 124us/sample - loss: 0.4139 - acc: 0.9429 - val_loss: 0.3540 - val_acc: 0.9111\n","Epoch 135/200\n","105/105 [==============================] - 0s 108us/sample - loss: 0.4138 - acc: 0.9238 - val_loss: 0.3509 - val_acc: 1.0000\n","Epoch 136/200\n","105/105 [==============================] - 0s 169us/sample - loss: 0.4132 - acc: 0.9429 - val_loss: 0.3500 - val_acc: 1.0000\n","Epoch 137/200\n","105/105 [==============================] - 0s 107us/sample - loss: 0.4113 - acc: 0.9524 - val_loss: 0.3495 - val_acc: 1.0000\n","Epoch 138/200\n","105/105 [==============================] - 0s 105us/sample - loss: 0.4128 - acc: 0.9429 - val_loss: 0.3497 - val_acc: 1.0000\n","Epoch 139/200\n","105/105 [==============================] - 0s 125us/sample - loss: 0.4131 - acc: 0.9429 - val_loss: 0.3482 - val_acc: 0.9111\n","Epoch 140/200\n","105/105 [==============================] - 0s 94us/sample - loss: 0.4100 - acc: 0.9238 - val_loss: 0.3467 - val_acc: 1.0000\n","Epoch 141/200\n","105/105 [==============================] - 0s 102us/sample - loss: 0.4083 - acc: 0.9524 - val_loss: 0.3454 - val_acc: 0.9778\n","Epoch 142/200\n","105/105 [==============================] - 0s 98us/sample - loss: 0.4117 - acc: 0.9429 - val_loss: 0.3445 - val_acc: 0.9778\n","Epoch 143/200\n","105/105 [==============================] - 0s 100us/sample - loss: 0.4074 - acc: 0.9333 - val_loss: 0.3436 - val_acc: 0.9778\n","Epoch 144/200\n","105/105 [==============================] - 0s 140us/sample - loss: 0.4058 - acc: 0.9429 - val_loss: 0.3434 - val_acc: 0.9556\n","Epoch 145/200\n","105/105 [==============================] - 0s 133us/sample - loss: 0.4052 - acc: 0.9333 - val_loss: 0.3426 - val_acc: 1.0000\n","Epoch 146/200\n","105/105 [==============================] - 0s 155us/sample - loss: 0.4079 - acc: 0.9429 - val_loss: 0.3418 - val_acc: 1.0000\n","Epoch 147/200\n","105/105 [==============================] - 0s 152us/sample - loss: 0.4151 - acc: 0.9429 - val_loss: 0.3458 - val_acc: 0.9778\n","Epoch 148/200\n","105/105 [==============================] - 0s 122us/sample - loss: 0.4077 - acc: 0.9524 - val_loss: 0.3420 - val_acc: 1.0000\n","Epoch 149/200\n","105/105 [==============================] - 0s 130us/sample - loss: 0.4038 - acc: 0.9524 - val_loss: 0.3401 - val_acc: 1.0000\n","Epoch 150/200\n","105/105 [==============================] - 0s 104us/sample - loss: 0.4014 - acc: 0.9524 - val_loss: 0.3395 - val_acc: 0.9111\n","Epoch 151/200\n","105/105 [==============================] - 0s 90us/sample - loss: 0.4020 - acc: 0.9333 - val_loss: 0.3381 - val_acc: 1.0000\n","Epoch 152/200\n","105/105 [==============================] - 0s 132us/sample - loss: 0.4049 - acc: 0.9429 - val_loss: 0.3420 - val_acc: 0.9778\n","Epoch 153/200\n","105/105 [==============================] - 0s 114us/sample - loss: 0.4027 - acc: 0.9429 - val_loss: 0.3370 - val_acc: 0.9778\n","Epoch 154/200\n","105/105 [==============================] - 0s 98us/sample - loss: 0.3989 - acc: 0.9429 - val_loss: 0.3360 - val_acc: 1.0000\n","Epoch 155/200\n","105/105 [==============================] - 0s 114us/sample - loss: 0.4000 - acc: 0.9429 - val_loss: 0.3374 - val_acc: 0.9111\n","Epoch 156/200\n","105/105 [==============================] - 0s 103us/sample - loss: 0.3991 - acc: 0.9048 - val_loss: 0.3369 - val_acc: 0.9111\n","Epoch 157/200\n","105/105 [==============================] - 0s 96us/sample - loss: 0.3987 - acc: 0.9238 - val_loss: 0.3337 - val_acc: 1.0000\n","Epoch 158/200\n","105/105 [==============================] - 0s 145us/sample - loss: 0.3981 - acc: 0.9524 - val_loss: 0.3341 - val_acc: 0.9111\n","Epoch 159/200\n","105/105 [==============================] - 0s 103us/sample - loss: 0.3981 - acc: 0.9333 - val_loss: 0.3342 - val_acc: 0.9111\n","Epoch 160/200\n","105/105 [==============================] - 0s 137us/sample - loss: 0.3981 - acc: 0.9143 - val_loss: 0.3325 - val_acc: 1.0000\n","Epoch 161/200\n","105/105 [==============================] - 0s 94us/sample - loss: 0.3939 - acc: 0.9524 - val_loss: 0.3312 - val_acc: 1.0000\n","Epoch 162/200\n","105/105 [==============================] - 0s 134us/sample - loss: 0.3949 - acc: 0.9524 - val_loss: 0.3393 - val_acc: 0.9778\n","Epoch 163/200\n","105/105 [==============================] - 0s 97us/sample - loss: 0.4029 - acc: 0.9238 - val_loss: 0.3352 - val_acc: 0.9778\n","Epoch 164/200\n","105/105 [==============================] - 0s 126us/sample - loss: 0.3976 - acc: 0.9429 - val_loss: 0.3323 - val_acc: 1.0000\n","Epoch 165/200\n","105/105 [==============================] - 0s 111us/sample - loss: 0.3932 - acc: 0.9429 - val_loss: 0.3304 - val_acc: 1.0000\n","Epoch 166/200\n","105/105 [==============================] - 0s 132us/sample - loss: 0.3925 - acc: 0.9429 - val_loss: 0.3300 - val_acc: 1.0000\n","Epoch 167/200\n","105/105 [==============================] - 0s 101us/sample - loss: 0.3955 - acc: 0.9429 - val_loss: 0.3353 - val_acc: 0.9778\n","Epoch 168/200\n","105/105 [==============================] - 0s 96us/sample - loss: 0.3953 - acc: 0.9333 - val_loss: 0.3264 - val_acc: 1.0000\n","Epoch 169/200\n","105/105 [==============================] - 0s 135us/sample - loss: 0.3902 - acc: 0.9619 - val_loss: 0.3259 - val_acc: 0.9778\n","Epoch 170/200\n","105/105 [==============================] - 0s 127us/sample - loss: 0.3921 - acc: 0.9333 - val_loss: 0.3273 - val_acc: 1.0000\n","Epoch 171/200\n","105/105 [==============================] - 0s 118us/sample - loss: 0.3927 - acc: 0.9429 - val_loss: 0.3281 - val_acc: 0.9111\n","Epoch 172/200\n","105/105 [==============================] - 0s 149us/sample - loss: 0.3920 - acc: 0.9048 - val_loss: 0.3246 - val_acc: 0.9778\n","Epoch 173/200\n","105/105 [==============================] - 0s 118us/sample - loss: 0.3885 - acc: 0.9238 - val_loss: 0.3237 - val_acc: 1.0000\n","Epoch 174/200\n","105/105 [==============================] - 0s 106us/sample - loss: 0.3857 - acc: 0.9429 - val_loss: 0.3243 - val_acc: 1.0000\n","Epoch 175/200\n","105/105 [==============================] - 0s 130us/sample - loss: 0.3873 - acc: 0.9429 - val_loss: 0.3237 - val_acc: 1.0000\n","Epoch 176/200\n","105/105 [==============================] - 0s 93us/sample - loss: 0.3863 - acc: 0.9524 - val_loss: 0.3220 - val_acc: 1.0000\n","Epoch 177/200\n","105/105 [==============================] - 0s 102us/sample - loss: 0.3883 - acc: 0.9238 - val_loss: 0.3230 - val_acc: 1.0000\n","Epoch 178/200\n","105/105 [==============================] - 0s 100us/sample - loss: 0.3863 - acc: 0.9429 - val_loss: 0.3206 - val_acc: 0.9778\n","Epoch 179/200\n","105/105 [==============================] - 0s 135us/sample - loss: 0.3826 - acc: 0.9429 - val_loss: 0.3196 - val_acc: 1.0000\n","Epoch 180/200\n","105/105 [==============================] - 0s 102us/sample - loss: 0.3870 - acc: 0.9333 - val_loss: 0.3218 - val_acc: 1.0000\n","Epoch 181/200\n","105/105 [==============================] - 0s 132us/sample - loss: 0.3846 - acc: 0.9429 - val_loss: 0.3204 - val_acc: 1.0000\n","Epoch 182/200\n","105/105 [==============================] - 0s 112us/sample - loss: 0.3821 - acc: 0.9429 - val_loss: 0.3212 - val_acc: 1.0000\n","Epoch 183/200\n","105/105 [==============================] - 0s 98us/sample - loss: 0.3829 - acc: 0.9524 - val_loss: 0.3179 - val_acc: 1.0000\n","Epoch 184/200\n","105/105 [==============================] - 0s 111us/sample - loss: 0.3798 - acc: 0.9429 - val_loss: 0.3175 - val_acc: 0.9778\n","Epoch 185/200\n","105/105 [==============================] - 0s 115us/sample - loss: 0.3798 - acc: 0.9429 - val_loss: 0.3169 - val_acc: 0.9778\n","Epoch 186/200\n","105/105 [==============================] - 0s 119us/sample - loss: 0.3805 - acc: 0.9333 - val_loss: 0.3156 - val_acc: 0.9778\n","Epoch 187/200\n","105/105 [==============================] - 0s 122us/sample - loss: 0.3790 - acc: 0.9429 - val_loss: 0.3151 - val_acc: 1.0000\n","Epoch 188/200\n","105/105 [==============================] - 0s 143us/sample - loss: 0.3787 - acc: 0.9333 - val_loss: 0.3151 - val_acc: 1.0000\n","Epoch 189/200\n","105/105 [==============================] - 0s 112us/sample - loss: 0.3792 - acc: 0.9524 - val_loss: 0.3146 - val_acc: 0.9778\n","Epoch 190/200\n","105/105 [==============================] - 0s 107us/sample - loss: 0.3783 - acc: 0.9333 - val_loss: 0.3158 - val_acc: 0.9111\n","Epoch 191/200\n","105/105 [==============================] - 0s 139us/sample - loss: 0.3773 - acc: 0.9333 - val_loss: 0.3147 - val_acc: 0.9333\n","Epoch 192/200\n","105/105 [==============================] - 0s 101us/sample - loss: 0.3758 - acc: 0.9333 - val_loss: 0.3131 - val_acc: 0.9778\n","Epoch 193/200\n","105/105 [==============================] - 0s 139us/sample - loss: 0.3752 - acc: 0.9333 - val_loss: 0.3123 - val_acc: 0.9778\n","Epoch 194/200\n","105/105 [==============================] - 0s 125us/sample - loss: 0.3748 - acc: 0.9429 - val_loss: 0.3116 - val_acc: 1.0000\n","Epoch 195/200\n","105/105 [==============================] - 0s 120us/sample - loss: 0.3737 - acc: 0.9524 - val_loss: 0.3112 - val_acc: 1.0000\n","Epoch 196/200\n","105/105 [==============================] - 0s 112us/sample - loss: 0.3766 - acc: 0.9619 - val_loss: 0.3115 - val_acc: 0.9778\n","Epoch 197/200\n","105/105 [==============================] - 0s 128us/sample - loss: 0.3732 - acc: 0.9333 - val_loss: 0.3105 - val_acc: 1.0000\n","Epoch 198/200\n","105/105 [==============================] - 0s 118us/sample - loss: 0.3731 - acc: 0.9429 - val_loss: 0.3158 - val_acc: 0.9778\n","Epoch 199/200\n","105/105 [==============================] - 0s 97us/sample - loss: 0.3765 - acc: 0.9429 - val_loss: 0.3098 - val_acc: 1.0000\n","Epoch 200/200\n","105/105 [==============================] - 0s 94us/sample - loss: 0.3707 - acc: 0.9524 - val_loss: 0.3091 - val_acc: 1.0000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f1a6ce7c1d0>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"y-SgSSdRcih5","colab_type":"text"},"source":["### Model Prediction"]},{"cell_type":"code","metadata":{"id":"GBgKZkhkcih6","colab_type":"code","outputId":"fdaae758-a8ec-4d98-82f9-aaf94ada014c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model.predict(X_test[0:1])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.03031101, 0.6129535 , 0.35673553]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"n8rd0jjAjyTR","colab_type":"code","outputId":"d59289f7-bc70-4af2-e304-c578b53d2981","colab":{"base_uri":"https://localhost:8080/","height":77}},"source":["y_test[0:1]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Species_Iris-setosa</th>\n","      <th>Species_Iris-versicolor</th>\n","      <th>Species_Iris-virginica</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>73</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Species_Iris-setosa  Species_Iris-versicolor  Species_Iris-virginica\n","73                    0                        1                       0"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"P32ASP1Vjt0a","colab_type":"text"},"source":["### Save the Model"]},{"cell_type":"code","metadata":{"id":"uL61054Uiszp","colab_type":"code","colab":{}},"source":["model.save('iris.h5')"],"execution_count":0,"outputs":[]}]}